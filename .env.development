# This file serves as both a sample .env file that can be modified and copied
# to .env for use in local development AND as a source for environment
# variables while running spider processes in docker as a part of the
# search-services repo.

# If using this out of docker as a .env file be sure to adjust the
# pythonpath to include the local path to the project, e.g.:
# PYTHONPATH=${PYTHONPATH}:/path/to/local/code/searchgov-spider
SCRAPY_LOG_LEVEL="INFO"

# Job Control
SPIDER_CRAWL_SITES_FILE_NAME="crawl-sites-development.json"
SPIDER_SCRAPY_MAX_WORKERS="1"
SPIDER_URLS_API="https://jsonplaceholder.typicode.com/posts"

# Opensearch
OPENSEARCH_ENABLED="True"
SEARCHOPENSEARCH_INDEX="development-i14y-documents-searchgov"
OPENSEARCH_SEARCH_DOMAIN="http://localhost:9300"
OPENSEARCH_ADMIN_USER="username"
OPENSEARCH_ADMIN_PASS="password"

# Elasticsearch
ES_HOSTS="http://localhost:9200"
ES_USER="username"
ES_PASSWORD="password"
SEARCHELASTIC_INDEX="development-i14y-documents-searchgov"

# SPIDERMON related variables
SPIDER_SPIDERMON_ENABLED="False"
SEARCH_AWS_ACCESS_KEY_ID=""
SEARCH_AWS_SECRET_ACCESS_KEY=""

# DAP
DAP_EXTRACTOR_SCHEDULE="*/5 * * * *"
DAP_API_BASE_URL="https://api.gsa.gov/analytics/dap/v2.0.0"
DATA_GOV_API_KEY=""

# SEARCHGOV DB
DB_HOST="127.0.0.1"
DB_PORT="3306"
DB_USER="root"
DB_PASSWORD=""
DB_NAME="usasearch_development"
